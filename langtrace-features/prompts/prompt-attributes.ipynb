{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Attributes Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the Langtrace features of creating prompts in the prompt registry, accessing those prompts through the Langtrace API to use with OpenAI's GPT-4o, and providing this prompt data in your traces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites:\n",
    "* Sign-up for a free account on [LangTrace](https://langtrace.ai/).\n",
    "* Create a project then generate an API key. Refer to quickstart documentation for help.\n",
    "* Create a prompt registry and a prompt in the recently created project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create Prompt in Langtrace Prompt Registry\n",
    "Navigate to the Prompts tab in Langtrace and click 'Create Prompt Registry'\n",
    "\n",
    "![image info](../assets/prompts_tab.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then fill out the form to create your first Prompt Registry. \n",
    "\n",
    "![image info](../assets/create_prompt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on the newly created prompt, select Create Prompt, fill out the form with your prompt, then click Save.\n",
    "\n",
    "![image info](../assets/new_prompt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see the following for your prompt. Be sure to copy the Prompt Registry ID and select the Go Live button for the following steps.\n",
    "\n",
    "![image info](../assets/prompts_page.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Install & Initialize Langtrace\n",
    "First, we need to install and import the neccessary libraries then initialize Langtrace with our API key. In a production environment, you should use environment variables or a secure method to store your API key.\n",
    "\n",
    "#### Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai langtrace-python-sdk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langtrace_python_sdk import langtrace, get_prompt_from_registry, inject_additional_attributes\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Langtrace and OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "langtrace.init(api_key='8032673cc3f998540b946a3c0cfae5eee7a3786694a043463e466b6fab242f05')\n",
    "client = OpenAI(api_key='sk-******')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Access your prompt using the Langtrace API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Prompt Registry ID saved from Step 1, access the prompt using the following code and print it to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langtrace_prompt = get_prompt_from_registry(prompt_registry_id='clxxkaoy10001f3l45jq6xghn')\n",
    "print(langtrace_prompt['value'])\n",
    "\n",
    "# You should see the following printed if you're following along with the tutorial:\n",
    "# You are an expert software engineer. Your job is to answer software related questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define a function to capture the prompts in the traces\n",
    "Access the prompt, id, and version to be passed in your traces to langtrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = langtrace_prompt['value']\n",
    "prompt_id = langtrace_prompt['id']\n",
    "prompt_version = langtrace_prompt['version']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to call OpenAI's API to pass to Langtrace's 'inject_additional_attributes' function to capture the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_llm_call():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, call the 'test_llm_call' function by passing it into the following function. To successfully see the promp id and version in the Langtrace client, be sure the additional attributes you are passing match exactly what is in the example ('prompt_id' and 'prompt_version')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = inject_additional_attributes(test_llm_call, attributes={'prompt_id': id, 'prompt_version' : version})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see the following trace in Langtrace!\n",
    "![image info](../assets/prompt_in_langtrace.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    " \n",
    "In this notebook, we've created a simple python function to test the Langtrace Prompt API and insertion of additional attributes into your traces. This demonstrates how easy it is to integrate these tools into your AI applications.\n",
    " \n",
    "Some potential next steps:\n",
    "* Try different versions of your prompts to test application performance\n",
    "* Create variables in your langtrace prompts to make them more accurate for each user\n",
    "* Analyze Langtrace data to optimize performance and identify bottlenecks"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
